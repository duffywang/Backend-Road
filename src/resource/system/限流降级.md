## 关于故障

故障产生的原因可以分为以下几大类

网络问题：网络链接出现问题、宽带出现堵塞。

性能问题：数据库慢SQL、Java full gc、硬盘IO过大、CPU飙高、内存不足。

安全问题：被网络攻击，如DDoS。

运维问题：系统不断进行更新和修改。

管理问题：没有梳理出关键服务及服务依赖关系。

硬件问题：硬盘损坏、网卡故障、机房掉电。

故障是正常的，而且是常见的，"Everything will fails"

不要尝试着去避免故障，而是把处理故障的代码当成正常的功能做在架构里写在代码中。



## 降级

降级(Degradation)本质是为了解决资源不足和访问量过大的问题，暂时牺牲掉一些东西以保证整个系统的平稳运行。

对服务调用方来说，服务降级可以在被调用服务不可用时，通过临时的替代方案向上提供有损服务，保证业务柔性可用；

对于服务提供方来说，服务降级极大的减轻了对服务提供方的压力，有助于服务提供方快速恢复。

降级是一种思想，限流、熔断是措施。

降级的三种模式：

强制降级：在强制降级模式下，客户端对某一服务的调用会全部降级，降级后会根据配置的降级策略返回。强制降级的开关需要由开发负责人手动打开和关闭，一般用于在紧急情况下对后端调用做全部降级，并在恢复正常后手动关闭降级开关。

失败降级：在失败降级模式下，客户端始终会调用后端服务，但仅当调用失败时才进行服务降级，这个时候将根据配置的降级策略返回。

自动降级：在自动降级模式下，客户端会根据当前的服务调用情况，自动识别是否需要降级。如果需要降级，会根据配置的降级策略返回；如果不需要降级，就进行正常的服务调用。

注意事项：

清楚定义降级的关键条件，如请求量过大、响应时间过长、失败次数过多。

梳理业务的功能，哪些是must-have，哪些是nice-to-have。

## 熔断

熔断的灵感来源于保险丝，当电路短路时，自动跳闸，电路就会自动断开，电器收到保护。

重试机制如果错误太多，短时间内得不到修复，那么重试的就没有意义，应开启熔断操作。防止应用程序不断地尝试执行可能会失败的操作，可保护后端不会过载；熔断器也可以诊断错误是否已经修正，如果已修正，应用程序会再次尝试调用操作。

简单来说熔断器就像是针对容易导致错误的操作一种代理，这种代理记录最近调用发生错误的次数，决定是继续操作还是立即返回。

举个栗子，应用A部署了3台机器，其中一台机器上出现超时而报错，请求还是会通过负载均衡算法请求故障的机器，出现整个1/3请求出现超时报错，影响整个系统可用性，在Mapi对异常进行统计，发现发往某一台机器的错误数或错误率达到设定的阈值，就在一定的时间内不继续往该台机器发请求。

请求标记有三种状态，分别是正常（NORMAL）、降级(DEGRADE)、测试(SINGLE_TEST)

熔断器有三种状态，每次状态切换的时候会发出一个事件，这种信息可以用来监控服务的运行状态：

未开启（CLOSE）：需要一个调用失败的计数器，最近调用失败数超过阈值则切换到开启状态。此时开启一个超时时钟，当该时钟时间超过，切换到半开启状态。

开启（OPEN）：首先判断是否需要试探，如果不进行试探则对应用程序的请求会立即返回降级响应。

半开启（HALF-OPEN）：允许应用程序一定数量的请求去调用服务，如果这些请求对服务的调用成功，那么可以认为之前导致的错误已经修正，此时将熔断器切换到未开启状态，错误计数器重置；如果失败，切换到开启状态，重置计时器给系统一定的时间来修正错误。半开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次拖垮。


### 触发策略

1、请求总数达到阈值，默认20。

2、请求失败率达到阈值，默认1%。

3、请求失败数达到阈值，默认2，如果只要失败率条件，这个条件可以设置为0。

### 恢复策略

在滑动时间窗口内，如果失败率低于设定的熔断阈值1%时，会尝试恢复，默认每隔5s放一个请求，如果还是失败，就再等一个周期，恢复策略：

立即恢复：全量恢复，不推荐。

正常恢复：每秒恢复10%的流量，可自定义。

快速恢复：按2的幂次方恢复流量，按每秒2%，4%，8%，16%，32%速度恢复。

限时恢复：即在规定时间内恢复完成，恢复速度是匀速的。

附：常见参数说明
```
Key: 唯一表示，这个业务方在使用时需要注意，类似Hystrix的commandKey，不能缺省

fallBackMethod: 当发生熔断时，业务方需要执行的降级方法，不能缺省

isActive：默认为true，是否启用

isForceOpen：默认为false，强制开启熔断

isDegradeOnException: 默认为false，当发生异常时是否降级

sleepWindowInMilliseconds: 默认为5000，当发生熔断时，试探请求的时间窗口

errorThresholdPercentage: 默认为1，滑动窗口内的失败率阈值

requestVolumeThreshold：默认为20，滑动窗口内的请求总数阈值

errorThresholdCount：默认为2，滑动窗口内的请求失败数阈值

rollingStatsTime：默认为10，统计数据的时间窗口

ignoreExceptions: 指定忽略的异常，被忽略的异常不会计入接口健康统计，抛出的异常需要业务处理

circuitBreakerTriggerRangeDataList：分时间段的熔断条件

timeoutInMilliseconds：超时时间
```

## 限流

限流可以认为是服务降级的一种，限流就是限制系统的输入和输出流量来达到保护系统的目的，很多地方都有限流的思想，如数据库连接池，线程池，Nginx下的用于限制瞬时并发连接数的limit_conn模块，限制每秒平均速率的limit_req模块。

限制接口每秒可以通过的请求数，超出的流量可以选择延迟处理、部分拒绝或者直接拒绝。

### 限流策略

拒绝服务：把多的请求拒绝掉，统计哪个客户端来的流量最多，直接拒绝掉，这种方式可以把一些不正常的或有恶意的高并发访问拦在外面。在Pigeon中，可限制某个客户端应用请求的最大QPS，如果客户端请求QPS超过阈值，服务端返回RejectedException；限制服务端某个服务方法对某个客户端应用请求最大QPS，如.EchoService服务接口的echo方法，对客户端应用account-service的最大单机QPS为200。

服务降级：这样让服务有更多的资源处理更多的请求，一种降级的方式是把一些不重要的服务给停掉，把CPU、内存或是数据的资源让给更重要的功能；另一种是不再返回全量数据，只返回部分数据，以牺牲一致性的方式来获得更大的性能吞吐。

特权请求：资源不够用，只能把有限的资源分给重要的用户，如VIP用户。

延时处理：一般有队列缓冲大量的请求，如果队列满了，那么也只能拒绝用户了，使用缓冲队列只是为了减缓压力，一般用于应对短暂的峰刺请求。

### 限流的实现方式

计数器方式：简单暴力，直接维护一个计数器counter，限制一秒钟能够通过的请求数，算法的实现思路就是从第一个请求开始计时，在接下来1秒内，当一个请求进来，counter计数加1，若counter大于100，开启拒绝请求以保护系统，后续的请求就会全部拒绝。可以通过AtomicLong#incrementAndGet()方法计数器加1并返回最新值，通过这个值和阈值进行比较。缺点是产生“突刺现象”。

队列算法：优先级队列，先处理高优先级的队列，再处理低优先级的队列。为了避免低优先队列被饿死，一般是分配不同比例的处理时间到不同的队列上，即带权重的队列，如处理权重为3的队列上3个请求后，再去权重为2的队列上处理2个请求，最后再去权重为1的队列上处理1个请求。如果处理过慢，就会导致队列满而开始触发限流。

漏斗算法：一个固定的容量漏斗，按照固定速率流出水滴，如果流入水滴超出漏斗的容量，则流入的水滴溢出（被丢弃）。

令牌桶算法：对于很多应用场景来说，除了要求能够限制数据的平均传输速率，还要求允许某种程度的突发流量，这时候漏斗算法可能就不合适了，可采用令牌桶算法。在一个桶内按照一定的速率放入一些令牌（token)，只有拿到令牌才能处理请求；令牌桶有一个容量，当令牌桶满了的时候，再向其中放入令牌则会丢弃。在流量小的时候攒钱，流量大的时候可以快速处理，使用令牌桶算法。

统一限流器

### 限流策略

1、单机限流

单机固定限流，基于令牌桶算法实现，可以应对突发流量，默认桶中会保存设置qps数量的令牌。

2、集群限流（非精确）

单机限流，通过指定集群的QPS，单机QPS会随着业务扩容缩容，根据业务的机器数动态的计算。

3、集群限流（精确）

基于Redis的计数实现精确集群限流，每次限流需要和Redis进行通信，有1ms左右的性能损耗，如果Redis挂了，将不进行限流。

4、集群限频

内部通过uuid关键字，实现各个uuid的访问频次

比如有用户a，b，c，d.... z，访问接口/index，目前的需求是限制每个用户的访问频次 2次/ 5s

可以通过集群限频并基于redis的计数实现，用户id+接口名作为key，过期时间为5s，保存在redis中

5、集群配额

和集群限频的实现原理一致，但是每种策略的限流只能创建一个，如果遇到下面的需求，可以使用该策略，例如：

需要限制每个用户的访问频次 2次/ 5s

同时还要限制每天的调用总数为2000

对于这二个需求，就可以创建一个集群配额，限制每个用户每天的调用总次数



